name: Scraper de Precios

on:
  # Para ejecutarlo manualmente desde la pesta√±a "Actions"
  workflow_dispatch:
  # Para ejecutarlo cada hora, todos los d√≠as
  schedule:
    - cron: '0 * * * *' # 'Minuto 0 de cada hora'

jobs:
  scrape:
    runs-on: ubuntu-latest # Usar√° un servidor Linux

    steps:
      # 1. Clona tu repositorio al servidor
      - name: Checkout del repositorio
        uses: actions/checkout@v3

      # 2. Configura Node.js
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18' # Usamos Node.js versi√≥n 18

      # 3. ¬°¬°EL PASO QUE FALTABA!!
      # Instala las dependencias (puppeteer, puppeteer-extra, etc.)
      - name: Instalar dependencias
        run: npm install

      # 4. Ejecuta el script de scraping
      - name: Correr el script
        run: node scraper.js

      # 5. Guarda los cambios (el precios.json actualizado) en el repo
      - name: Commit de los archivos
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add precios.json
          # Solo hace commit si hay cambios reales en el archivo
          git commit -m "Actualizaci√≥n autom√°tica de precios ü§ñ" -a || echo "No hay cambios en los precios"
          git push

      # 6. Guardar capturas si hay error
      - name: Guardar capturas de error (si existen)
        uses: actions/upload-artifact@v4
        if: failure() # Solo se ejecuta si un paso anterior fall√≥
        with:
          name: screenshots-de-error
          path: error-*.png # Sube todos los archivos que empiecen con 'error-'
